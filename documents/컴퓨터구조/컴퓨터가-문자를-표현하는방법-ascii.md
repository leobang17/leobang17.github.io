---
title: "컴퓨터가 문자를 표현하는 방법 - ASCII, Unicode"
createdAt: 2024-01-04
---

> 컴퓨터는 문자를 binary로 어떻게 표현할까? 

## ASCII Code

##### 초기의 ASCII Code - 7bit

7bit의 코드로 <u>128 (2^7^)개의 다른 값을 표현</u>할 수 있다. 이를 통해 대문자와 소문자 알파벳, 0-9까지의 숫자와 구두점 같은 값들도 7bit 청크의 binary로 인코딩할 수 있게 되었다.

- 7bit로 표현할 수 있는 0 ~ 2^7^ - 1 까지의 경우의 수가 ASCII 테이블에 매핑되었다.
- 8bit 중 1bit를 남겨놓은 이유는 나머지 1bit를 에러 검출을 위한 용도로 비워두었기 때문이다. (pairity bit)

##### Extended ASCII - 8bit

초기의 ASCII Code의 문제는 영어를 위해서만 설계되었다는 점이었다. 이후에 8bit의 binary로 표현할 수 있는 Extended ASCII를 표준화하면서 다양한 특수문자들과 로마자를 지원하게 된다.

##### 인코딩 오류가 나는 이유

각자 인코딩/디코딩에 사용하는  `문자 <-> binary 데이터` 테이블이 다르기 때문이다.

Extended ASCII가 영어 외의 라틴어 계열을 추가적으로 지원했지만, 라틴어 계열이 아닌 어족을 사용하는 언어 역시 존재한다.

이를 위해 Extended ASCII의 여분 공간에 라틴어 대신 자국의 언어를 테이블에 할당하게 되는데··· 

- 이렇게 되면 동일한 8bit의 binary 정보도, 어떤 ASCII Table을 이용해서 해석하느냐에 따라 이상한 값이 나올 수 있다.
- 예를들어, `갈` 이라는 문자가 한국어로 인코딩하는 ASCII Table에서는 `101101111`에 매핑되어있다고 치자. 
- `갈`을 의도로 인코딩한 8bit의 문자를 라틴어로 이루어진 ASCII Table로 해석하면? `ㄱ`이 아닌 전혀 이상한 특수 문자가 튀어나올 수 있는 것이다.

아시아 국가가 컴퓨터 분야에 진입하자 문제는 더 커졌다. 한자를 사용하는 일본과 중국의 경우는 도저히 8bit 만으로 테이블을 감당할 수 없었다. 

> ##### 한글의 사정 
>
> 한글의 사정도 비슷했다. 한글을 표현할 수 있는 표준으로는 <u>조합형</u>과 <u>완성형</u>이 있다.
>
> - 조합형: 테이블에 28개의 자모만을 매핑해두고, 이를 추후에 결합하는 방식
> - 완성형: 결합된 글자를 테이블에 매핑하는 방식
>
> 완성형을 사용하려면 당시 8836가지의 한글 문자만 표현 가능했지만 자모로 이루어진 한 글자의 전체 경우의 수는 <u>160만</u>에 육박한다···



## Unicode의 등장 (91년)

이러한 인코딩 문제 때문에 각각의 국가적인 제도를 없애고 **하나의 보편적인 인코딩 표준**에 대한 요구가 등장한다. 이에 따라 4Byte의 넉넉한 공간에 세상의 모든 문자를 할당한 표준을 만들었는데, 이 것이 **Unicode**이다.

- 4Byte는 32bit로, 2^32^가지 경우의 수를 나타낼 수 있다. 약 42억자를 담을 수 있는 셈.

Unicode를 통해 하나의 표준으로 전세계의 모든 언어와 추가된 수학적인 기호, 그리고 심지어 이모지들까지 지원하게 된다. 이렇게 넣어도 아직 공실률이 60%가 넘는다고 하니, 더 큰 단위의 문자 표현 방식은 미뤄두어도 되겠다.

> 참고로 유니코드의 스페이스를 가장 많이 점령하고 있는 문자 1위는 한자이며, 2위가 한글이다. 조합형으로 활용하기 때문. 

가장 일반적인 버전은 <u>**16bit**의 binary 청크</u>를 활용한다. *2^16^가지, 즉 65536가지의 경우의 수를 표현*할 수 있다

- 16진수 2개를 이어붙인 것으로 표현한다. 

- 한자의 총 자수 가 8만여자이니, 아쉽긴 하지만 안쓰는 한자를 빼자면 이 정도면 충분하다고 판단했나보다.
- 그냥 모든 문자를 다 표현하자!는 의미로 32bit만을 이용하는게 UTF-32.



## UTF (Unicode Transformation Format)

UTF는 유니코드를 실제로 저장하고 전송하기 위한 여러 인코딩 방식 중의 하나이다. UTF는 유니코드의 코드 포인트를 byte로 변환하는 규칙을 정의한다. 

> ##### Unicode와 UTF의 차이
>
> Unicode는 문자 집합(Character Set)을 정의하는 <u>국제 표준</u>이다. 이는 전 세계의 모든 문자에 고유한 코드 포인트(숫자)를 할당하여 텍스트를 표현한다. UTF는 <u>unicode를 컴퓨터에서 어떻게 표현할지를 나타내는 인코딩 방식</u>이다. 

현재 웹은 거의 표준처럼 UTF-8으로 대동단결하게 되었다. 

##### UTF-8

가장 널리 이용되는 <u>가변길이</u> Unicode 인코딩 방식이다. 유니코드라고 하면 십중팔구 UTF-8이라고 생각해도 좋을 정도로 현재 웹에서 표준과 가까이 쓰이는 호환성이 좋은 인코딩 방식. 가변길이 인코딩 방식인 이유는, 문자에 따라 표현하는 byte 길이가 다르기 때문이다.

- ASCII 대역으로 표현할 수 있는 문자는 1byte로 표현한다. (영문자 + 숫자 + 기타 특수기호)
- 그 외 다양한 언어의 문자는 2byte 이상으로 표현한다. 가장 크게는 4byte를 모두 이용해 표현한다. 
- 한글은 3 byte를 할애하는 구간이다. `감` 한글자를 위해 16진수 6개가 들어가는 것.
  - 그래서 <u>한글로 작성된 파일의 경우 파일 크기가 최대 1.5배</u>로 늘어나게 된다.

##### UTF-16

<u>고정길이</u> 인코딩 방식으로 유니코드의 대부분 종류의 문자를 2byte (16bit)로 표현한다. 일부는 4byte로 표현하기도 한다. 2 byte면 16진수가 4개이다. 

- BMP(Basic Multilingual Plane)에 속하는 문자들은 2바이트로 표현되고, SMP(Supplementary Multilingual Plane)에 속하는 일부 문자들은 4바이트로 표현된다.

1111 1111 1111 1111

Big-Endian: 사람이 읽는 순서와 유사하게 가장 큰 단위 (좌측에서 우측)부터 나열한다.

Litttle-Endian: 바이트를 역순으로 나열하는 방식. 우측에서부터 좌측으로 나열한다.

##### UTF-32

32bit (4byte)로 고정된 길이의 문자 인코딩 방식이다. 모든 문자를 4byte로 표현한다. 

