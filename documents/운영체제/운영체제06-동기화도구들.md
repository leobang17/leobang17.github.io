---
title: "공룡책 운영체제06 - 동기화"
createdAt: 2022-10-17
---

# 6. 동기화 도구들

> **이 장의 목표**
>
> - critical section (임계영역) 문제를 정의하고 Race Condition (경쟁 조건)을 설명한다.
> - 메모리 장벽, compare-and-swap 연산 및 Atomic 변수를 사용하여 critical section 문제에 대한 하드웨어적 해결책을

## 6.1 배경

##### ++ 연산의 예시

다음과 같은 instruction `count++` 은 겉보기엔 나눌 수 없는 단위의 연산같아 보인다. 하지만 이를 기계어로 interprete한다면 다음과 같이 구현된다.

``` 
register1 = count
register1 = register1 + 1
count = register
```

쪼갤 수 없는 연산 같았던 `++` 도 기계어로 따지자면 3단위로 나눌 수 있다. 따라서 서로 다른 두 프로세스가 공유 변수에 대해 concurrent하게 (병렬적으로) `++` 연산을 시행한다면, `++` 도중에 Context Switching이 일어날 수 있으므로 데이터의 inconsistency가 발생하게 된다.

##### fork()의 예시

서로 다른 두 프로세스가 concurrency한 상황에서, `fork()`을 호출한다고 가정하자.

`fork()` 시스템 콜은 자식프로세스를 생성하고, 생성된 프로세스의 프로세스 식별자 (pid)를 부모 프로세스로 반환한다. 프로세스 식별자를 생성된 프로세스에 할당할 때 이용되는 공유 변수인 *next_available_pid*가 존재하며, 이 때 이 변수에 대해 race condition이 발생한다. 

상호 배제 (Mutex; Mutual Exclusion)이 보장되지 않는다면 *next_available_pid*를 확인하는 순간 context switching이 일어나 동일한 프로세스 식별자가 서로 다른 두 프로세스에 할당될 수도 있다.

### 6.1.1 Race Condition (경쟁상황)

위와 같이, 동시에 여러 개의 프로세스가 동일한 자료를 접근하여 조작하고, 그 실행의 결과가 논리적으로 동일하지 않고 접근이 발생한 특정 순서에 의존하여 달라지는 상황을 **Race Condition**이라고 한다. (= 접근 순서에 따라 inconsistency가 일어나는 상황)

Race Condition을 회피하기 위해, 우리는 어떤 형태로든 프로세스들이 synchronized (동기화) 되도록 할 필요가 있다.



## 6.2 Critical Section Problem (임계구역 문제)

6.1.1에서 정의한 Race Condition을 피하기 위해 프로세스들을 Sychronize 시킬 필요가 있다고 했다. 모든 프로세스 동기화에 대한 논의는 Critical-Section Problem이라 불리는 문제로부터 시작한다. Critical-Section Problem은 코드영역을 4가지로 나눈다.

##### Entry-Section (진입 구역)

각 프로세스는 Critical-Section으로 진입하기 위해 진입 허가를 먼저 요청해야한다. 이러한 요청을 구현하는 부분이다.

##### Critical-Section (임계 영역)

Cooperative process들이 공유변수를 다루는 영역이다. 임계영역에 진입했을 경우, 다른 프로세스들은 그들의 Critical-Section에 진입해서는 안된다.

##### Exit-Section (퇴출 구역)

Critical-Section을 탈출했기에 이제 다른 프로세스가 코어를 선점해도 괜찮다는 신호를 보내야한다. Entry-Section에서 획득한 permission을 반납하는 요청을 구현한다.

##### Remainder-Section (나머지 구역)

위 세 구역을 제외한, context switch 당해도 괜찮은 = 공유 변수에 접근/조작하지 않는 구역을 의미한다.



### 6.2.1 Critical-Section Problem을 해결하기 위한 3가지 요구사항

임계영역 문제를 완벽히 해결하기 위해서는 다음 3가지 조건이 요구된다.

##### 6.2.1.1 Mutex; Mutual-Exclusion (상호 배제) - 서로 동시에 임계영역에 진입하지 말 것

어떠한 프로세스 Pi가 자신의 Critical-Section에서 CPU를 점유했다면, *다른 프로세스들은 그들 자신의 Critical-Section에 진입할 수 없다!*

> Critical-Section에 진입했다고 해서 context switching이 아예 막힌 것은 아니다! 다른 프로세스의 Remainder-Section으로의 진입은 가능하다.

임계영역 문제를 해결하기 위한 가장 기본적인 조건이다. 그런데, Mutex를 구현하고 나면 항상 다음 두 문제인 Deadlock과 Starvation이 따라온다..!

##### 6.2.1.2 Progress (진행) - Deadlock을 회피하자 

현재 Critical-Section에 진입한 프로세스가 없고 Entry-Section에 있는 프로세스만 있다고 가정하자. 다음으로 누가 Critical Section에 진입할 것인지 결정하는데 참여할 수 있는 프로세스는 Remainder-Section에서 실행중이지 않은 프로세스들 (= Entry 혹은 Critical 혹은 Exit-Section에 있는 프로세스들만)뿐이다. 이 선택은 무한정 연기되어선 (Deadlock) 안되며, progressive 해야한다.

##### 6.2.1.3 Bounded waiting (한정 대기) - Starvation을 회피하자

프로세스가 Entry-Section에서 permission을 요청한 후로부터 그 요청이 획득될 때까지 다른 프로세스들이 자신의 Critical-Section에 진입하는 횟수에는 제한이 있어야 한다. 즉, 우선순위의 문제 때문에 영원히 임계영역으로 진입을 요청만 하고 매번 다른 프로세스에게 기회를 뺏기는 일은 없어야 한다. (기다리는 시간이 길어질 수록 우선순위를 높여준다.)



### 6.2.2 Multi-Core 환경에서의 어려움

Single-Core 환경을 가정한다면 Critical-Section 문제 해결을 가볍게 해결할 수 있다. Shared Variable을 수정하는 동안 (= 임계영역에 있는 동안) interrupt가 발생하는 것을 막으면 된다.

Multi-processor 환경에서는 실행하기 굉장히 어려워진다. 코어 별로 임계영역에 진입했을 시 interrupt를 죄다 막아버려야 하는데, 이렇게 되면 시스템의 성능이 굉장히 떨어진다. 



## 6.3 Peterson의 해결안

Peterson의 알고리즘은 고전적인 소프트웨어 기반 해결책 중 Critical-Section 문제를 가장 올바르게 다뤘다. 

다만, classic한 소프트웨어와 현대 컴퓨터 구조가 `load`와 `store`와 같은 기본적인 기계어를 수행하는 방식이 다르기 때문에, 현대 컴퓨터구조에서도 올바르게 실행된다고 보장할 수는 없다.

Peterson의 해결안은 Critical-Section과 Remainder-Section을 번갈아가며 실행하는 두 개의 프로세스를 가정한다. 프로세스는 P0과 P1로 번호를 매긴다. Peterson 해결안의 두 프로세스는 다음 두 변수를 공유하게 된다.

### 6.3.1 Peterson's Solution이 공유하는 두 변수

``` java
int turn;
boolean flag[2];
```

##### turn

Critical-Section으로 진입할 차례를 나타낸다. `turn == 0`일 경우 P0이 Critical-Section을 실행할 수 있다.

##### flag

프로세스가 Critical-Section으로 진입할 준비가 되었다는 것을 나타낸다. `flag[0]`이 `true`라면 P0이 임계구역으로 진입할 준비가 되었다는 뜻이다. 

### 6.3.2 Peterson's Solution

Pi의 코드 구현이다.

``` java
while (true) {
  flag[i] = true;
  turn = ;
  while (flag[j] && turn == j) {};
  /* 
    임계영역의 코드들 
  */
  flag[i] = false;
  
  /* 
  	Remainder-Section
  */
}
```

Pi은 `flag[j] == false` 이거나 `turn == i`일 때 임계영역에 진입할 수 있다. P0과 P1은 동시에 while 문을 지나칠 수 없으며, 어느 하나가 while문을 지나 Critical-Section에 진입했다면 다른 하나는 while 문의 공회전에 걸린 채, Critical-Section에 진입한 프로세스가 자신의 flag를 false로 설정해줄 때까지 기다려야 한다. 

이와 같이 Peterson의 해결책은 Critical-Section 문제의 요구사항 3가지인 Mutex, Progress, Bounded-waiting을 모두 만족한다. 또한, 가정은 2개의 프로세스이지만 n개의 프로세스로도 확장할 수 있다. 하지만 한계가 있었으니...

### 6.3.3 Peterson's Solution의 한계

위에서 언급했듯이 현대 컴퓨터 구조에서는 항상 동기화가 이루어질 것이라고 보장할 수 없다. `load`와 `store`의 기계어 레벨로 쪼개게 된다면 임계영역에 진입하기 위한 조건문인 `while` 구문 역시 하나의 Atomic한 (원자적인) instruction이 아니기 때문이다. 

Entry Section에서 while문의 조건인 `while(flag[j] && turn == j)`을 실행하는데, 앞 부분까지만 실행하고 중간에 context switching이 일어난다면? 피터슨의 해결안도 동기화에 실패하게 된다. 

그럼에도 Peterson의 해결안을 공부하는 이유는 개념적으로 완벽하며, CSP의 세가지 요구사항을 모두 증명가능하게 구현해내기 때문이다. 실제 상황에서 기계어로 실행되다보니 보장이 안될 뿐, 고수준 언어에서 '개념적으로' 생각할 경우 보장되는 일이다.



## 6.4 동기화를 위한 Hardware Support

> ##### Software 기반 해결책과 Hardware 기반 해결책
>
> 위의 피터슨 해결책과 같이 *알고리즘만으로 해결하고자 하는 접근법*을 Software 기반 해결책이라 한다. 피터슨 알고리즘은 OS 혹은 하드웨어 명령어의 지원을 받지 않고 순수히 알고리즘만으로 Mutex를 구현했다.
>
> 하지만 6.3.3과 같이 소프트웨어 기반 해결책은 최신 컴퓨터 구조에서 100% 보장되지 않을 수 있다. 따라서 이를 위한 Hardware 레벨의 명령어를 지원한다. 이러한 명령어를 통해 더 추상적인 동기화가 가능하다.



### 6.4.1 Memory Barrier (메모리 장벽)

6.3절에서 시스템은 명령어의 순서를 재정렬할 수 있다는 것과 이러한 정책이 신뢰할 수 없는 데이터 상태로 이어질 수 있다는 것을 보았다. (책 참고) 이러한 순서를 보장하기 위해 `memory_barrier()` 명령어를 지원한다.

``` java
while (!flag)
  memory_barrier();
print(x);
```

`flag` 값이 `x` 값보다 먼저 적재될 것을 보장한다.

``` java
x = 100;
memory_barrier();
flag = true;
```

`x` 값이 `flag` 값보다 먼저 배정될 것을 보장한다.

**Memory Barrier는 매우 저수준의 연산이며, 일반적으로 Mutex를 보장하는 코드를 개발하는 커널 개발자만 사용하므로 넘어가자..!** 

### 6.4.2 Hardware Instructions (하드웨어 명령어들)

`++`나 두 변수를 swap하는 연산들은 고수준 언어 구현만 보면 Atomic한 명령어 같지만 기계어 수준으로 내려가면 이들은 1개 이상의 연산이 합쳐진 복합적인 명령어로, 중간에 context switching이 일어난다면 데이터의 일관성을 보장할 수 없게 된다. 

따라서 많은 현대 기계들은 이러한 연산들을 하나로 묶어 Atomic한 실행을 보장하는 하드웨어 명령어들을 제공한다. `test_and_set()`, `compare_and_swap()`과 같은 명령어들은 interrupt되지 않은 하나의 단위로서 제공된다. 이들을 조건으로 Critical-Section에 진입하면 보다 간단하게 임계영역 문제를 해결할 수 있다. (적어도 Mutex는 보장하므로)

**하지만 일반적으로 하드웨어 명령어들도 응용 레벨에서는 직접 사용되지는 않는다.** 그럼 왜 배우냐? 응용 레벨에서 이용할 수 있는 Critical-Section 문제를 다루는 도구인 Atomic Variable을 구현하는데 이용되는 기본적인 요소이기 때문이다. 

### 6.4.3 Atomic Variable

Atomic Variable은 단일 변수에 대한 race condition이 발생할 수 있는 상황에서 Mutex를 보장하는데 이용되는 특수한 변수이다. Atomic Variable의 내부 구현은 `compare_and_swap()`이나 `test_and_set()` 등의 hardware instruction을 이용해 구현되어있다.

Atomic Variable은 '원자적 갱신'은 제공하지만 모든 상황에서 Race Condition을 완벽히 해결하지는 않는다. 응용레벨에서도 일반적으로 사용되지만 공유 데이터 한 개의 '갱신'에만 제한되는 경우가 많다. 따라서 보다 일반적인 상황에서 Race Condition을 해결하는 더 강력한 도구가 필요하다...



## 6.5 Mutex Locks

6.4의 Hardware Instruction이 Atomic한 명령어를 제공해줬다. 그래도 매번 Critical-Section에 진입하는 코드 (Entry-Section)는 해당 명령어들을 기반으로 **직접 구현**해야했다. (특정 조건 하에서 진입할 수 있도록) 

Mutex Lock은 Critical-Section으로의 진입 / 탈출을 추상화한 명령어를 제공한다. Entry-Section과 Exit-Section을 직접 구현할 필요 없이 `acquire()`, `release()` 메서드를 이용해 진입/탈출 구간을 정의하면 된다.

### 6.5.1 Mutex Lock이 제공하는 메서드들

`acquire()`와 `release()` 함수 호출은 원자적으로 수행되어야 한다. 따라서 mutex 락은 6.4절의 CAS를 사용하여 구현된다. Mutex 락은 `available`이라는 boolean  변수를 이용해 '락'의 가용 여부를 표시한다. `available`이 true일 경우 락을 획득할 수 있고, 그 반대일 경우는 락을 획득하기 위해 기다려야 한다.

##### 6.5.1.1 acquire()

``` java
acquire() {
  while (!available) {};
  /* busy waiting */ 
  available = false;
}
```

락을 획득하는 메서드이다. 임계영역에 진입했음을 알리며, 어떤 프로세스가 `acquire()`를 호출하여 락을 획득할 경우 다른 프로세스는 락을 획득할 수 없다, 즉 그 자신의 임계영역에 진입할 수 없다.

##### 6.5.1.2 release()

``` java
release() {
  available = true;
}
```

락을 반납하는 메서드이다.

### 6.5.2 Busy Waiting은 꼭 나쁜가? 

Mutex 락의 구현을 보면 `acquire()`를 이용해 락을 획득하기 위해 while loop을 계속해서 호출하게 된다. 이를 **busy waiting** 상태라 부르며, 락을 획득할 수 있을때까지 프로세스가 *공회전하며* 기다리기 때문에 Mutex 락을 **스핀락**이라 부르기도 한다.

busy waiting은 확실히 여러 프로세스가 하나의 CPU 코어를 time sharing하며 concurrent하게 실행되는 상태에서는 낭비이다. 다른 프로세스가 생산적으로 사용할 수 있는 CPU 주기를 낭비하고 의미 없는 while loop을 도는데 이용하기 때문이다. 

그러나 멀티 프로세서 환경에서 놀고 있는 CPU가 여러 대 있다면? 아무거나 선점해서 busy waiting하고 있다가 lock이 풀리면 바로 진입할 수 있다. 특히 락이 짧은 시간 동안 유지될 경우 멀티 코어 시스템에서는 스핀락을 선호한다. 

> **얼마나 짧아야 하는가?**
>
> 스핀락을 사용하지 않을 경우 ready queue에 대기하고 있다가 락을 획득할 수 있는 시점에 CPU를 점유하게 된다. 이 경우 context switching이 2번 일어나게 된다. 첫 번째는 쓰레드를 waiting queue로 옮기기 위한 context switching이고, 두번째는 락을 획득할 수 있을 때 ready queue에서 CPU로 올리기 위한 context switching이다. 락이 지속되는 시간이 이 dispatch latency 시간보다 짧을 경우 스핀락을 사용하게 된다.



## 6.6 Semaphore

세마포어는 기찻길에 있는 신호기를 뜻한다. 진입해도 되는지 알려주는 신호기, 세마포어를 통해 CSP를 해결해보자.

### 6.6.1 고전적인 Semaphore

세마포어를 뜻하는 변수 S는 정수 변수이다. 세마포어 S는 초기화한 이후에는 두 개의 Atomic한 연산 메서드인 `wait()`과 `signal()`을 통해서만 접근할 수 있다. 두 메서드는 반드시 원자적으로 수행되어야 한다. S가 0이 되었을 경우 모든 쓰레드는 대기하게 되고, signal을 통해 세마포어를 반납하며 1씩 증가시킨다. 

##### wait()

``` java
wait(S) {
  while (S <= 0) 
    ; // busy waiting
  S--; 
}
```

##### signal()

``` java
signal(S) {
  S++;
}
```

#### 6.6.1.2 Binary Semaphore (이진 세마포어)

정수 변수인 세마포어 S가 0 혹은 1의 값을 가지는 세마포어를 뜻한다. 하나의 쓰레드만 Critial Section으로 진입을 할 수 있으며, 진입을 대기하는 쓰레드의 경우 busy waiting을 수행하기 때문에 **사실상 Mutex 락과 동일하다.** 실제로 몇몇 시스템에서는 Mutex를 제공하기 위해 Mutex락 대신 이진 세마포어를 이용한다. 

#### 6.6.1.3 Counting Semaphore

세마포어 S가 2 이상의 값을 가진, 제한 없는 domain을 가지는 세마포어를 뜻한다. 만약 Counting 세마포어를 이용할 때 n개의 쓰레드가 n개 미만의 공유변수에 접근한다면 Critical-Section 문제를 동일하게 겪게 될 것이다. 예를들어, `S = 5`인 세마포어를 이용해 5개의 쓰레드가 동일한 `sum` 변수를 for 문으로 10,000까지 증가시킨다면? CSP 때문에 50,000까지 도달하지 못할 것이다. 

이처럼 Counting Semaphore를 이용해 동기화 문제를 해결하고자 한다면 접근하는 공유 변수 역시 S와 동일한 개수여야 한다. 접근하고자 하는 sum 변수가 5개라면 각 10,000씩 올바르게 더해져있을 것.

Counting 세마포어는 주로 유한한 개수를 지닌 자원에 대한 접근을 제어하고자 할 때 이용된다.

### 6.6.2 Semaphore 구현 

위의 고전적인 세마포는 S를 정수 변수로 두었고, busy waiting을 이용해 `wait()`을 수행한다. 이번 구현에서는 busy waiting 대신, 세마포어를 대기하는 상황에서는 프로세스 자신을 waiting queue에 삽입하고, 세마포어를 이용할 준비가 되었을 때 waiting queue에서 꺼내 ready queue로 이동하는 방식을 택해보자. 

##### semaphore

``` C++
typedef struct {
  int value;
  struct process *list;
} semaphore;
```

##### wait()

``` c++
wait(semaphore *S) {
  S->value++;
  if (S->value < 0) {
    add this process to S->list; // pseudo code
    sleep();
  }
}
```

##### signal()

``` c++
signal(semaphore *S) {
  S->value--;
  if (S->value <= 0) {
    remove a process P from S->list; // pseudo code
    wakeup(P);
  }
}
```

`sleep()` 연산은 자기를 호출한 프로세스를 일시 중지시킨다. `wakeup(P)` 연산은 일시중지된 프로세스 `P` 를 재개시킨다. 이 두 연산은 OS의 기본적인 시스템 콜로 제공된다. 

busy waiting을 수행하는 고전적인 세마포의 경우 S값에 대해 음수를 허용하지 않지만, 6.6.2의 구현은 고전적인 세마포의 값 검사와 값 감소의 순서를 바꾸었으므로 음수를 허용한다. 세마포어가 0일 경우에 임계구역에 접근할 수 있으며, 0 이하의 음수일 경우 접근하지 못한다. S의 절대값은 세마포를 대기하고 있는 프로세스들의 수이다. 



## 6.7 Monitor

세마포어와 뮤텍스 락이 동기화를 위해 편리하고 효과적으로 쓰일 수 있지만, 이는 발견하기 힘든 timing 에러를 야기하기도 한다. 프로그래머가 악의적으로 이용하건 초보 프로그래머가 실수로 잘못 이용하건 메서드들을 적확한 순서로 이용하지 않는다면 발견하기 힘든 치명적인 동기화 오류를 야기한다. 뮤텍스를 써도, 세마포어를 써도 Timing Error는 여전히 발생할 수 있다. 

보다 고수준의 락을 걸 수있는 방식인 Monitor 기법을 알아보자. 

### 6.7.1 모니터 ADT 

모니터 type은 모니터 내부에서 Mutex가 보장되는, 프로그래머가 정의한 일련의 연산자 집합을 포함하는 ADT이다. 모니터 type은 변수들의 선언을 포함하고 있는데, 이 변수들의 값은 그 type에 해당하는 한 인스턴스의 상태를 정의한다. 

모니터 형의 표현은 다른 프로세스들이 직접 사용할 수 없다. 따라서 모니터 내에 정의된 함수만이 오직 모니터 내에 지역적으로 선언된 변수들과 형식 매개변수들에만 접근할 수 있다. 마찬가지로 모니토 내의 지역 변수는 오직 지역 함수만이 접근할 수 있다.

모니터 structure는 모니터 안에 항상 하나의 프로세스만이 활성화 되도록 보장해준다. 프로그래머들은 이와 같은 동기화 제약조건을 명시적으로 코딩할 필요가 없다. 



### 6.7.2 Java의 동기화, Monitor-Lock 

자바가 충실하게 Monitor를 따르고 있다. 따라서 Java의 동기화를 이해한다면 Monitor를 이해했다고 볼 수 있다. 

Java에서는 Monitor와 유사한 Monitor-Lock, 혹은 Intrinsic-Lock (본질적 락)을 제공한다. (세마포어보다는 본질적이므로 Intrinsic-Lock이라 부른다.)

Java는 기본적인 실행단위가 프로세스가 아니라 쓰레드였다. 따라서 쓰레드 동기화를 위한 concurrency 메커니즘이 Monitor-Lock이다.

이번까지는 임계영역에 진입하는 것을 암시적으로 선언했다. 세마포어 혹은 뮤텍스를 이용해서 들어갔지만, 이는 암시적인 진입. Java에서는 임계영역에 대한 코드블록을 명시적으로 선언한다.

해당 코드 블록에는 Monitor-Lock을 획득해야만 진입할 수 있다. 

Monitor-Lock을 수행해야하는 객체 인스턴스를 지정할 수 있다.

메서드에 선언하면 메서드 코드블록 전체가 critical section으로 지정된다. 이 때 모니터 락을 가진 객체 인스턴스는 this이다.

